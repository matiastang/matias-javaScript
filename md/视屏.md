<!--
 * @Descripttion: 
 * @version: 
 * @Author: matias tang
 * @Date: 2020-09-25 16:59:54
 * @LastEditors: matias tang
 * @LastEditTime: 2020-09-25 17:35:52
-->
# 视屏

1,视频码率一般设多大？

视频码率就是数据传输时单位时间传送的数据位数，一般我们用的单位是kbps即千位每秒。通俗一点的理解就是取样率，单位时间内取样率越大，精度就越高，处理出来的文件就越接近原始文件。
但是文件体积与取样率是成正比的，所以几乎所有的编码格式重视的都是如何用最低的码率达到最少的失真，围绕这个核心衍生出来的cbr（固定码率）与vbr（可变码率），都是在这方面做的文章，不过事情总不是绝对的，举例来看，对于一个音频，其码率越高，被压缩的比例越小，音质损失越小，与音源的音质越接近。

对于1080P的视频而言，蓝光视频的码率是20Mb/s，一般下载的视频码率大都是10Mb/s，一些IPCamera/无人机的码率是2～8Mb/s，而很多视频网站的码率甚至低于5M/s

同等分辨率的情况下，码率越大，清晰度越大，但同时对网络带宽的占用也越大，具体码率该设置为多少，需要看应用的具体场景了。

2. 播放中出现“跳跃”和“花屏”现象？

“跳跃”和“花屏”现象绝大多数原因是网络传输过程中由于信号不好导致丢失了“关键帧”/“参考帧” 引起的，下面来进一步解释。



视频在网上传播之前是需要压缩的，而简单来解释视频压缩的核心思想就是：每隔10~50帧取视频中的一帧图像作为“关键帧”，而随后的几帧图像由于时间/空间的冗余和相关性，我们只需记录其与关键帧的“差异”信息即可，这样视频文件就可以不用把每一帧完整的图像数据全部保存下来，从而起到了节省空间的效果。



由此可见，如果丢失掉了“关键帧”，随后的几帧图像自然就无法正常地解码了，因此产生了“花屏”现象。



从技术的角度，怎么解决“花屏”现象呢？——当我们在视频传输过程中，通过帧序号发现丢帧后，可以跳过随后的非“关键帧”，直到遇到下一个关键帧再送入解码。这样的确可以解决“花屏”现象，但是由于跳跃了很多帧，因此会出现视频图像的不连续情况（即“跳跃”现象）。



3. 播放过程中出现“卡顿”现象？



由于网络是很不稳定的，因此，音视频数据的传输也是时快时慢的，在播放网络视频流的过程中，一定要根据时间戳来决定何时解码何时显示，而不是来一帧就播放一帧，另外，添加一定数量的“帧缓冲区”可以有效地降低由于网络抖动带来的“卡顿”现象。



4. 音视频实时传输的延时主要来自哪里 ？



（1） 编码器/解码器一般需要缓冲2～4帧

（2） 编码/解码的耗时

（3） 业务代码中的帧缓冲区

（4） 网络传输延时

（5） 代码中的数据拷贝



一般情况下，帧率为30f/s的视频，每缓冲n帧，就会增加1000/30*n毫秒的延时。因此，要想减少延时，则必须通过分析和测试找到上述每一部分的延时，尽量减少数据的拷贝和缓冲。



5. 边下边播的原理 ？



边下边播与播放本地文件其实差不多，只不过是文件数据不在本地，在播放器播放到指定位置之前，后台线程把需要的数据提前下载下来而已。


参考文章： https://blog.csdn.net/shuiniu1224/article/details/40921001

https://blog.csdn.net/datamining2005/article/details/72852064

## I帧,P帧,B帧

[I帧,P帧,B帧](https://blog.csdn.net/abcjennifer/article/details/6577934)

视频压缩中，每帧代表一幅静止的图像。而在实际压缩时，会采取各种算法减少数据的容量，其中IPB就是最常见的。
  
简单地说，`I帧是关键帧`，属于帧内压缩。就是和AVI的压缩是一样的。 P是向前搜索的意思。B是双向搜索。他们都是基于I帧来压缩数据。
`I帧`表示关键帧，你可以理解为这一帧画面的完整保留；解码时只需要本帧数据就可以完成（因为包含完整画面）
`P帧`表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧的画面差别的数据）
`B帧`是双向差别帧，也就是B帧记录的是本帧与前后帧的差别（具体比较复杂，有4种情况），换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累~。

一般平均来说，I的压缩率是7（跟JPG差不多），P是20，B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来保存多一些I帧，这样在相同码率下，可以提供更好的画质。

## RTMP、RTSP、HTTP协议

这三个协议都属于互联网 TCP/IP 五层体系结构中应用层的协议。理论上这三种都可以用来做视频直播或点播。但通常来说，直播一般用 RTMP、RTSP。而点播用 HTTP。下面分别介绍下三者的特点。

 

1，RTMP协议

（1）是流媒体协议。

（2）RTMP协议是 Adobe 的私有协议，未完全公开。

（3）RTMP协议一般传输的是 flv，f4v 格式流。

（4）RTMP一般在 TCP 1个通道上传输命令和数据。

 

2，RTSP协议

（1）是流媒体协议。

（2）RTSP协议是共有协议，并有专门机构做维护。.

（3）RTSP协议一般传输的是 ts、mp4 格式的流。

（4）RTSP传输一般需要 2-3 个通道，命令和数据通道分离。

 

3，HTTP协议

（1）不是是流媒体协议。

（2）HTTP协议是共有协议，并有专门机构做维护。 

（3）HTTP协议没有特定的传输流。 

（4）HTTP传输一般需要 2-3 个通道，命令和数据通道分离。

#### 可用的直播流地址

通常我们进行 RTMP/RTSP 开发时，除了可以自己搭建视频服务器来进行测试外。也可以直接使用一些电视台的直播地址，省时省力。
下面是我收集汇总的一些视频直播地址，亲测可用。

1，RTMP协议直播源

香港卫视：rtmp://live.hkstv.hk.lxdns.com/live/hks

2，RTSP协议直播源

珠海过澳门大厅摄像头监控：rtsp://218.204.223.237:554/live/1/66251FC11353191F/e7ooqwcfbqjoo80j.sdp

大熊兔（点播）：rtsp://184.72.239.149/vod/mp4://BigBuckBunny_175k.mov
 
3，HTTP协议直播源
香港卫视：http://live.hkstv.hk.lxdns.com/live/hks/playlist.m3u8

CCTV1高清：http://ivi.bupt.edu.cn/hls/cctv1hd.m3u8

CCTV3高清：http://ivi.bupt.edu.cn/hls/cctv3hd.m3u8

CCTV5高清：http://ivi.bupt.edu.cn/hls/cctv5hd.m3u8

CCTV5+高清：http://ivi.bupt.edu.cn/hls/cctv5phd.m3u8

CCTV6高清：http://ivi.bupt.edu.cn/hls/cctv6hd.m3u8

苹果提供的测试源（点播）：http://devimages.apple.com.edgekey.net/streaming/examples/bipbop_4x3/gear2/prog_index.m3u8

### 播放软件推荐：VLC

要播放视频直播流，或者测试一个直播视频地址是否可以使用。这里推荐 VLC 媒体播放器。功能强大且跨平台。支持 Windows、Mac OS、Linux、Android、iOS。

官网地址：http://www.videolan.org/
打开播放器，选择菜单中“媒体”->“打开网络串流...”。在弹出页面中填入视频地址即可。

## httpflv、RTMP、hls、dash

[httpflv、RTMP、hls、dash对比](https://blog.csdn.net/qq756684177/article/details/81518692?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)

1，协议使用份额

如今国内90%的面向大众的直播平台都是采用的rtmp和httpflv的混合，hls很少，而国外大部分采用的dash，少部分用hls和其他协议。

2，先简单的描述下这些协议

httpflv：这种直播传输实际上就是利用的flv文件的特点，只需要一个matedata和音视频各自header，后面的音视频数据就可以随意按照时间戳传输，当然视频得按照gop段来传输，这种直播数据实际上就是一个无限大的http传输的flv文件，视频地址类似：

http://mywebsite.com/live.flv，客户端利用flv特性，可以一边接受数据边解码播放。

rtmp：rtmp是adobe研发的开放协议，rtmp其实实质上也是传输的flv格式的数据，同样是flv tag，只不过rtmp在传输上封装了一层，比如rtmp不仅可以直播，也可以推流。rtmp的直播原理同样也是利用了flv文件的特性，只需要一些头信息，后面就可以随意传输音视频数据，达到边传输边播放。

hls：hls是苹果公司开发的协议，http轮询传输，该协议主要的数据格式是ts视频文件，大致就是将裸流h264和音频直播数据，切片封装成ts段，形成无数的ts小文件，客户端先请求一个m3u8文件，该文件内部会有一列ts文件的地址，客户端按照顺序依次播放ts，以此类推，hls地址类似：http://mywebsite.com/live.m3u8，hls在大部分的浏览器利用html5video是可以直接播放的。

dash：这个协议国内用的不多，http轮询传输，但是国外很多平台都在用，比如youtube直播，该协议是google公司研发的，和hls如出一辙，同样是将直播流数据切片，只不过不是ts文件，而是mp4或者3gp文件，又或者webm（vp8，vp9）文件，该协议同样和hls一样也是http传输，同样和hls主打的是“自适应动态码率”，大概意思就是当客户端网络不好的时候会无缝切换到低码率的路线。

3，各种协议延时及其原因

rtmp和httpflv：这两种协议大致数据一致，所以延时原因都是差不多的。按理说tcp流式传输直播因该都是延时极低的，为什么rtmp和httpflv还有延时呢？原因在h264上，rtmp和httpflv都是传输的flv tag，视频tag的数据平常就是h264数据，h264解码有个IBP，I是关键帧，是一帧完整的图像，必须要先有个I才能解码后面的BP，BP帧可以随便少，但是I帧不能少，所以I帧必须是在flv tag传输中第二个传输的（第一个是h264spspps），但是I帧在h264流里不是常有的，是隔一段才有个I帧，这个一段的间隔，俗称GOP，当编码时候GOP设置很短，当客户端连接上来，服务器会以最快速度找到流中最近I帧，从I帧开始发送直播数据，然而当GOP很长，I帧间隔很长，或者等待下一个I帧开始向新连接发送数据，或者在缓存里找最近的上一个I帧开始发送，这里就是rtmp和hls协议延时的关键了，在各大cdn平台，叫“rtmp秒开技术”，原理就是将推流数据二次解编码，设置很小的gop。总的来说，gop设置1s，在不考虑网络传输链路延时情况，数据延时最大就为1s，运气好刚好就是I帧就是0延时！

hls和dash：这两种协议延时原因大致都是差不多的，因为切片了，切成小端的文件，单独开始传输，这就是延时的关键了，当然可以设置切成小文件，越小延时越低。按理说dash切片要比hls稍微先进一点，所以延时上dash要比hls低，但是同样的，切片了，就注定延时。

4，关于解码播放的优劣势

首先，我想说flash真的要被淘汰了，rtmp和httpflv目前在网页上只能用flash或者插件的方式解码播放，而且flash在cpu和内存上都是占用很高。但是在客户端app上，不用网页播放，你可以不用担心这个问题。网页上播放，hls和dash的优势就体现出来了，可以用html5直接播放，当然理论上，dash的mp4的兼容性要比hls更好。而且hls和dash支持动态适应网络，无缝调节码率，这在网络波动很大的地方，这个功能不错，当然个人对于这个功能无所谓，我情愿线下看高清，也不线上看马赛克。

5，总结

对于各种面向用户的直播协议，我只讲了一部分的，当然还有更多，这里就不一一列举了。以后在浏览器上肯定是html5的市场，无论是hls也好dash也罢，或者新兴的很多websocket直播也好，技术反正是在不断更替的，或许有天，html5突然支持flv播放了呢？

## RTMP、WebRTC、UDP 三种互动直播方案的优劣比较
[RTMP、WebRTC、UDP 三种互动直播方案的优劣比较](https://www.oschina.net/news/95208/osc-yuanchuanghui-wuhan-**421)